(download)
# wget http://www.us.apache.org/dist/hive/hive-0.13.0/hive-0.13.0.tar.gz
# tar zxvf hive-0.13.0.tar.gz -C /usr/local/
# mv hive-0.13.0 hive
# chown -R hduser hive

(set env)
# su - hadoop
# export HADOOP_HOME=/usr/local/hadoop
# export HADOOP_PREFIX=/usr/local/hadoop
# export HIVE_HOME=/usr/local/hive
# export PATH=$HIVE_HOME/bin:$PATH

(start hive)
# cd /usr/local/hive
# $HADOOP_HOME/bin/hadoop fs -mkdir /tmp
# $HADOOP_HOME/bin/hadoop fs -mkdir /user/hive/warehouse
# $HADOOP_HOME/bin/hadoop fs -chmod g+w /tmp
# $HADOOP_HOME/bin/hadoop fs -chmod g+w /user/hive/warehouse
# bin/hive

(create table and test)
(download data)
# cd ~
# mkdir baseball
# cd baseball/
[hduser@localhost ~/baseball]# wget http://seanlahman.com/files/database/lahman2012-csv.zip
[hduser@localhost ~/baseball]# unzip lahman2012-csv.zip

(upload data to hdfs)
[hduser@localhost ~/baseball]# hadoop fs -mkdir baseball
[hduser@localhost ~/baseball]# hadoop fs -put *.csv baseball
[hduser@localhost ~/baseball]# hadoop fs -ls baseball
Found 24 items
......
......

(create Hive database)
[hduser@localhost ~/baseball]# hive
......
......
hive> create database baseball;
hive> create table baseball.master 
( lahmanID INT, playerID STRING, managerID INT, hofID STRING,  
  birthYear INT, birthMonth INT, birthDay INT, birthCountry STRING,  
  birthState STRING, birthCity STRING, deathYear INT, deathMonth INT, 
  deathDay INT, deathCountry STRING, deathState STRING, deathCity STRING, 
  nameFirst STRING, nameLast STRING, nameNote STRING, nameGiven STRING, 
  nameNick STRING, weight INT, height INT, bats STRING, throws STRING, 
  debut STRING, finalGame STRING, college STRING, lahman40ID STRING, 
  lahman45ID STRING, retroID STRING, holtzID STRING, bbrefID STRING ) 
ROW FORMAT DELIMITED FIELDS TERMINATED BY ',' ; 
hive> LOAD DATA LOCAL INPATH "Master.csv" OVERWRITE INTO TABLE baseball.master; 
hive> select * from baseball.master;
hive> quit;
