--> Configuration parameters at all the levels of the Hadoop framework, JVM, and OS can significantly impact performance of the Hadoop workloads.

A. Baseline Configuration
       1. Parameters that will influence the baseline configuration
             Modify these parameters to an acceptable level
             Goal: maximize the CPU and other hardware resources utilization of the cluster
             Parameters include:   
                 (1) Java heap size
                 (2) the number of Map/Reduce tasks
                 (3) the number of hardware threads available on the systems
                 (4) the available IO bandwidth
                 (5) the amount of available memory
             How to start:
                 (1) sufficient number of hard disk drives
                 (2) configure the number of Map/Reduce slots
                      * Map phase gets as much CPU resources as possible
                      * Reduce phase utilizes all the processor cores
                 (3)  configure Java heap size 
             Relevant Hadoop configuration parameters in mapred-site.xml
                 (1) mapred.map.tasks
                 (2) mapred.tasktracker.map.tasks.maximum
                 (3) mapred.reduce.tasks
                 (4) mapred.tasktracker.reduce.tasks.maximum
                 (5) mapred.map.child.java.opts
                 (6) mapred.reduce.child.java.opts
       2. Example:
             # of data disk drives per DataNode = 4
             # of map slots per hardware core = 2
             # of reduce slot per hardware core = 1
             Initial and max Java heap size for Map/Reduce JVM processes = 1GB
            * 3 JVM processes per hardware core at any given time consuming as much as 3GB heap per hardware core. There are 4GB RAM per hardware core available on the systems; the rest 1GB of memory per hardware core was left for OS buffers and caches.


(http://amd-dev.wpengine.netdna-cdn.com/wordpress/media/2012/10/Hadoop_Tuning_Guide-Version5.pdf)
